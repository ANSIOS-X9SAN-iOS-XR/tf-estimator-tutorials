{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Keras with MirroredStrategy\n",
    "In this lab, you will take the solution you created in Lab 03b and implement MirroredStrategy.  You will take a Keras Sequential Model and convert to estimator, then distribute with MirroredStrategy.\n",
    "\n",
    "It will be easiest to take the results you had from 4.2b and replace the model with the Keras Sequential Model.\n",
    "\n",
    "Helpful references:\n",
    "- https://www.tensorflow.org/guide/keras#multiple_gpus\n",
    "- https://keras.io/losses/#sparse_categorical_crossentropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3/dist-packages/h5py/__init__.py:34: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, Conv2D, MaxPooling2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Pipeline\n",
    "Reuse data pipeline components from previous labs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_tfrecord(example):\n",
    "    feature={'idx': tf.FixedLenFeature((), tf.int64),\n",
    "             'label': tf.FixedLenFeature((), tf.int64),\n",
    "             'image': tf.FixedLenFeature((), tf.string, default_value=\"\")}\n",
    "    parsed = tf.parse_single_example(example, feature)\n",
    "    image = tf.decode_raw(parsed['image'],tf.float64)\n",
    "    image = tf.cast(image,tf.float32)\n",
    "    image = tf.reshape(image,[32,32,3])\n",
    "    return image, parsed['label']\n",
    "\n",
    "def image_scaling(x):\n",
    "    return tf.image.per_image_standardization(x)\n",
    "\n",
    "def distort(x):\n",
    "    x = tf.image.resize_image_with_crop_or_pad(x, 40, 40)\n",
    "    x = tf.random_crop(x, [32, 32, 3])\n",
    "    x = tf.image.random_flip_left_right(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_input_fn(params):\n",
    "    dataset = tf.data.TFRecordDataset(\n",
    "        params['filenames'],num_parallel_reads=params['threads'])\n",
    "    dataset = dataset.map(parse_tfrecord, num_parallel_calls=params['threads'])\n",
    "    dataset = dataset.map(lambda x,y: (image_scaling(x),y),num_parallel_calls=params['threads'])\n",
    "    if params['mode']==tf.estimator.ModeKeys.TRAIN:\n",
    "        dataset = dataset.map(lambda x,y: (distort(x),y),num_parallel_calls=params['threads'])\n",
    "        dataset = dataset.shuffle(buffer_size=params['shuffle_buff'])\n",
    "    dataset = dataset.repeat()\n",
    "    dataset = dataset.batch(params['batch'])\n",
    "    dataset = dataset.prefetch(8*params['batch'])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = !ls ./data/cifar10_data_00*.tfrecords\n",
    "eval_files   = !ls ./data/cifar10_data_01*.tfrecords\n",
    "\n",
    "train_params = {'filenames': train_files,\n",
    "                'mode': tf.estimator.ModeKeys.TRAIN,\n",
    "                'threads': 16,\n",
    "                'shuffle_buff': 10000,\n",
    "                'batch': 200}\n",
    "\n",
    "eval_params  = {'filenames': eval_files,\n",
    "                'mode': tf.estimator.ModeKeys.EVAL,\n",
    "                'threads': 8,\n",
    "                'batch': 200}\n",
    "\n",
    "train_spec = tf.estimator.TrainSpec(input_fn=lambda: dataset_input_fn(train_params),max_steps=20000)\n",
    "eval_spec  = tf.estimator.EvalSpec(input_fn=lambda: dataset_input_fn(eval_params),steps=10,throttle_secs=60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO: Setup Keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "num_classes = 10\n",
    "model_params  = {'drop_out': 0.2, 'dense_units': 1024, 'learning_rate': 1e-3}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(128, (5, 5), padding='same', input_shape=[32, 32, 3]))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(128, (5,5)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(256, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2), strides=(2,2)))\n",
    "\n",
    "model.add(Conv2D(512, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(model_params['dense_units']))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Dropout(model_params['drop_out']))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "opt = tf.train.GradientDescentOptimizer(model_params['learning_rate'])\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer=opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "distribution = tf.contrib.distribute.MirroredStrategy(num_gpus=8)\n",
    "config = tf.estimator.RunConfig(save_checkpoints_secs = 300,\n",
    "                                keep_checkpoint_max = 5,\n",
    "                                session_config=tf.ConfigProto(allow_soft_placement=True, log_device_placement=True),\n",
    "                                train_distribute = distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./cnn_model/keras_model_dense1024_drop0.2_lr0.001_20180906093912\n"
     ]
    }
   ],
   "source": [
    "name = 'cnn_model/keras_model_'\n",
    "name = name + 'dense' + str(model_params['dense_units']) + '_'\n",
    "name = name + 'drop' + str(model_params['drop_out']) + '_'\n",
    "name = name + 'lr' + str(model_params['learning_rate']) + '_'\n",
    "name = name + time.strftime(\"%Y%m%d%H%M%S\")\n",
    "model_dir  = os.path.join('./',name)\n",
    "\n",
    "print(model_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DO: Create estimator from Keras Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_accuracy(labels, predictions):\n",
    "    pred_values = tf.argmax(predictions[model.output_names[0]], axis=1)\n",
    "    return {'accuracy': tf.metrics.accuracy(labels, pred_values)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using the Keras model provided.\n",
      "INFO:tensorflow:Using config: {'_num_worker_replicas': 1, '_model_dir': './cnn_model/keras_model_dense1024_drop0.2_lr0.001_20180906093912', '_evaluation_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f54384371d0>, '_keep_checkpoint_every_n_hours': 10000, '_device_fn': None, '_save_checkpoints_secs': 300, '_save_checkpoints_steps': None, '_master': '', '_global_id_in_cluster': 0, '_task_id': 0, '_save_summary_steps': 100, '_is_chief': True, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f54384370f0>, '_task_type': 'worker', '_service': None, '_session_config': allow_soft_placement: true\n",
      "log_device_placement: true\n",
      ", '_tf_random_seed': None, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "_estimator = keras.estimator.model_to_estimator(\n",
    "  keras_model=model, config=config, model_dir=model_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_num_worker_replicas': 1, '_model_dir': './cnn_model/keras_model_dense1024_drop0.2_lr0.001_20180906093912', '_master': '', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f563e1acda0>, '_keep_checkpoint_every_n_hours': 10000, '_device_fn': None, '_save_checkpoints_secs': 300, '_save_checkpoints_steps': None, '_evaluation_master': '', '_global_id_in_cluster': 0, '_task_id': 0, '_save_summary_steps': 100, '_is_chief': True, '_train_distribute': <tensorflow.contrib.distribute.python.mirrored_strategy.MirroredStrategy object at 0x7f563e1acdd8>, '_service': None, '_task_type': 'worker', '_session_config': allow_soft_placement: true\n",
      "log_device_placement: true\n",
      ", '_tf_random_seed': None, '_keep_checkpoint_max': 5, '_num_ps_replicas': 0, '_log_step_count_steps': 100}\n"
     ]
    }
   ],
   "source": [
    "estimator = tf.contrib.estimator.add_metrics(_estimator, my_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:CPU:0\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_CPU:0\n",
      "INFO:tensorflow:Device is available but not used by distribute strategy: /device:XLA_GPU:0\n",
      "INFO:tensorflow:Configured nccl all-reduce.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:batch_all_reduce invoked for batches size = 12 with algorithm = nccl, num_packs = 1, agg_small_grads_max_bytes = 0 and agg_small_grads_max_group = 10\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model/keras_model_dense1024_drop0.2_lr0.001_20180906093912/keras_model.ckpt\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./cnn_model/keras_model_dense1024_drop0.2_lr0.001_20180906093912/model.ckpt.\n",
      "INFO:tensorflow:loss = 2.3047607, step = 0\n",
      "INFO:tensorflow:global_step/sec: 43.3724\n",
      "INFO:tensorflow:loss = 2.2997313, step = 100 (2.308 sec)\n",
      "INFO:tensorflow:global_step/sec: 70.7925\n",
      "INFO:tensorflow:loss = 2.293725, step = 200 (1.412 sec)\n",
      "INFO:tensorflow:global_step/sec: 27.1991\n",
      "INFO:tensorflow:loss = 2.2933688, step = 300 (3.677 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.6774\n",
      "INFO:tensorflow:loss = 2.28633, step = 400 (5.996 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.793\n",
      "INFO:tensorflow:loss = 2.280726, step = 500 (5.955 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.2462\n",
      "INFO:tensorflow:loss = 2.2770863, step = 600 (6.156 sec)\n",
      "INFO:tensorflow:global_step/sec: 15.6338\n",
      "INFO:tensorflow:loss = 2.2726438, step = 700 (6.396 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.0086\n",
      "INFO:tensorflow:loss = 2.2642956, step = 800 (6.246 sec)\n",
      "INFO:tensorflow:global_step/sec: 16.8875\n",
      "INFO:tensorflow:loss = 2.2564552, step = 900 (5.922 sec)\n",
      "INFO:tensorflow:Saving checkpoints for 1000 into ./cnn_model/keras_model_dense1024_drop0.2_lr0.001_20180906093912/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.2442682.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.estimator.estimator.Estimator at 0x7f563e1acba8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run on 8 GPUs\n",
    "estimator.train(input_fn=lambda: dataset_input_fn(train_params),max_steps=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-09-06-09:44:29\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./cnn_model/keras_model_dense1024_drop0.2_lr0.001_20180906093912/model.ckpt-1000\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Evaluation [1/10]\n",
      "INFO:tensorflow:Evaluation [2/10]\n",
      "INFO:tensorflow:Evaluation [3/10]\n",
      "INFO:tensorflow:Evaluation [4/10]\n",
      "INFO:tensorflow:Evaluation [5/10]\n",
      "INFO:tensorflow:Evaluation [6/10]\n",
      "INFO:tensorflow:Evaluation [7/10]\n",
      "INFO:tensorflow:Evaluation [8/10]\n",
      "INFO:tensorflow:Evaluation [9/10]\n",
      "INFO:tensorflow:Evaluation [10/10]\n",
      "INFO:tensorflow:Finished evaluation at 2018-09-06-09:44:30\n",
      "INFO:tensorflow:Saving dict for global step 1000: accuracy = 0.231, global_step = 1000, loss = 2.2412996\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 1000: ./cnn_model/keras_model_dense1024_drop0.2_lr0.001_20180906093912/model.ckpt-1000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'accuracy': 0.231, 'global_step': 1000, 'loss': 2.2412996}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run on 1 GPU\n",
    "estimator.evaluate(input_fn=lambda: dataset_input_fn(eval_params),steps=10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
